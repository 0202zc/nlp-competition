{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertModel, BertConfig\n",
    "from transformers import AdamW\n",
    "from transformers import BertTokenizer\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import math\n",
    "import Levenshtein\n",
    "from pypinyin import lazy_pinyin\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 设置参数及文件路径\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # 程序可调用的GPU的ID\n",
    "max_seq_length = 60  # 输入文本最大长度\n",
    "learning_rate = 2e-5  # 模型学习率\n",
    "num_epochs = 7  # 训练最大迭代次数\n",
    "batch_size = 160  # 训练时每个batch中的样本数\n",
    "patience = 5  # 早停轮数\n",
    "file_name = 'baseline'  # 指定输出文件的名字\n",
    "model_name_or_path = './pretrained/ernie-gram'  # 预训练模型权重载入路径\n",
    "train_input = 'data/train/'  # 完成预处理的训练集载入路径\n",
    "test_input = './data/test/'  # 完成预处理的测试集载入路径\n",
    "random_seed = 42  # 随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=random_seed):\n",
    "    '''\n",
    "    固定随机种子\n",
    "    :param random_seed: 随机种子数目\n",
    "    :return:\n",
    "    '''\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 创建一个logger\n",
    "file_path = './log/'\n",
    "logger = logging.getLogger('mylogger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "timestamp = time.strftime(\"%Y.%m.%d_%H.%M.%S\", time.localtime())\n",
    "fh = logging.FileHandler(file_path + 'log_model1.txt')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('[%(asctime)s][%(levelname)s] ## %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    def __init__(self, s1, s2, label=None):\n",
    "        self.s1 = s1\n",
    "        self.s2 = s2\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    def __init__(self,\n",
    "                 choices_features,\n",
    "                 label\n",
    "\n",
    "                 ):\n",
    "        _, input_ids, input_mask, segment_ids = choices_features[0]\n",
    "        self.choices_features = {\n",
    "            'input_ids': input_ids,\n",
    "            'input_mask': input_mask,\n",
    "            'segment_ids': segment_ids\n",
    "        }\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def read_data(file_name):\n",
    "    examples = []\n",
    "    print(file_name)\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                line = line.split('\\t')\n",
    "                examples.append(InputExample(s1=line[0], s2=line[1], label=int(line[2]) if len(line) == 3 else None))\n",
    "    return examples\n",
    "\n",
    "\n",
    "def read_examples(dir, split='train'):\n",
    "    examples = []\n",
    "    for path in os.listdir(dir):\n",
    "        if split == 'train':\n",
    "            for file_name in os.listdir(dir + path):\n",
    "                example = read_data(os.path.join(dir + path, file_name))\n",
    "                examples.extend(example)\n",
    "        else:\n",
    "            example = read_data(os.path.join(dir, path))\n",
    "            examples.extend(example)\n",
    "    return examples\n",
    "\n",
    "\n",
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()\n",
    "\n",
    "\n",
    "def convert_examples_to_features(examples, tokenizer, max_seq_length,\n",
    "                                 is_training):\n",
    "    # 将文本输入样例，转换为数字特征，用于模型计算\n",
    "    features = []\n",
    "    for example_index, example in enumerate(examples):\n",
    "\n",
    "        s1 = tokenizer.tokenize(example.s1)\n",
    "        s2 = tokenizer.tokenize(example.s2)\n",
    "        _truncate_seq_pair(s1, s2, max_seq_length)\n",
    "\n",
    "        choices_features = []\n",
    "\n",
    "        tokens = [\"[CLS]\"] + s1 + [\"[SEP]\"] + s2 + [\"[SEP]\"]\n",
    "        segment_ids = [0] * (len(s1) + 2) + [1] * (len(s2) + 1)\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        padding_length = max_seq_length - len(input_ids) + 3\n",
    "        input_ids += ([0] * padding_length)\n",
    "        input_mask += ([0] * padding_length)\n",
    "        segment_ids += ([0] * padding_length)\n",
    "        choices_features.append((tokens, input_ids, input_mask, segment_ids))\n",
    "\n",
    "        label = example.label\n",
    "        if example_index < 1 and is_training:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"idx: {}\".format(example_index))\n",
    "            logger.info(\"tokens: {}\".format(' '.join(tokens).replace('\\u2581', '_')))\n",
    "            logger.info(\"input_ids: {}\".format(' '.join(map(str, input_ids))))\n",
    "            logger.info(\"input_mask: {}\".format(len(input_mask)))\n",
    "            logger.info(\"segment_ids: {}\".format(len(segment_ids)))\n",
    "            logger.info(\"label: {}\".format(label))\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                choices_features=choices_features,\n",
    "                label=label\n",
    "            )\n",
    "        )\n",
    "    return features\n",
    "\n",
    "\n",
    "def select_field(features, field):\n",
    "    return [\n",
    "        feature.choices_features[field] for feature in features\n",
    "    ]\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, model_name_or_path, hidden_size=768, num_class=2):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        self.config = BertConfig.from_pretrained(model_name_or_path, num_labels=num_class)\n",
    "        self.config.output_hidden_states = True\n",
    "        self.bert = BertModel.from_pretrained(model_name_or_path, config=self.config)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.weights = nn.Parameter(torch.rand(13, 1))\n",
    "        # self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_class)\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(0.2) for _ in range(5)\n",
    "        ])\n",
    "\n",
    "    def forward(self, input_ids, input_mask, segment_ids, y=None, loss_fn=None):\n",
    "        output = self.bert(input_ids, token_type_ids=segment_ids,\n",
    "                           attention_mask=input_mask)\n",
    "        last_hidden = output.last_hidden_state\n",
    "        all_hidden_states = output.hidden_states\n",
    "        batch_size = input_ids.shape[0]\n",
    "        ht_cls = torch.cat(all_hidden_states)[:, :1, :].view(\n",
    "            13, batch_size, 1, 768)\n",
    "        atten = torch.sum(ht_cls * self.weights.view(\n",
    "            13, 1, 1, 1), dim=[1, 3])\n",
    "        atten = F.softmax(atten.view(-1), dim=0)\n",
    "        feature = torch.sum(ht_cls * atten.view(13, 1, 1, 1), dim=[0, 2])\n",
    "        f = torch.mean(last_hidden, 1)\n",
    "        feature = torch.cat((feature, f), 1)\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                h = self.fc(dropout(feature))\n",
    "                if loss_fn is not None:\n",
    "                    loss = loss_fn(h, y)\n",
    "            else:\n",
    "                hi = self.fc(dropout(feature))\n",
    "                h = h + hi\n",
    "                if loss_fn is not None:\n",
    "                    loss = loss + loss_fn(hi, y)\n",
    "        if loss_fn is not None:\n",
    "            return h / len(self.dropouts), loss / len(self.dropouts)\n",
    "        return h / len(self.dropouts)\n",
    "\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt(\n",
    "                            (1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (\n",
    "                                    N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return acc, f1\n",
    "\n",
    "\n",
    "def set_lr(optimizer, value):\n",
    "    for p in optimizer.param_groups:\n",
    "        p['lr'] = value\n",
    "\n",
    "\n",
    "class EMA():\n",
    "    def __init__(self, model, decay):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "\n",
    "    def register(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def apply_shadow(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                self.backup[name] = param.data\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "\n",
    "\n",
    "def prob_postprocess(y_pred):\n",
    "    prior = np.array([0.41141412384687165, 0.5885858761531283])  # 训练集 正负样本比例\n",
    "    y_pred_uncertainty = -(y_pred * np.log(y_pred)).sum(1) / np.log(2)\n",
    "\n",
    "    threshold = 0.95\n",
    "    y_pred_confident = y_pred[y_pred_uncertainty < threshold]\n",
    "    y_pred_unconfident = y_pred[y_pred_uncertainty >= threshold]\n",
    "\n",
    "    right, alpha, iters = 0, 1, 1\n",
    "    post = []\n",
    "    for i, y in enumerate(y_pred_unconfident):\n",
    "        Y = np.concatenate([y_pred_confident, y[None]], axis=0)\n",
    "        for j in range(iters):\n",
    "            Y = Y ** alpha\n",
    "            Y /= Y.sum(axis=0, keepdims=True)\n",
    "            Y *= prior[None]\n",
    "            Y /= Y.sum(axis=1, keepdims=True)\n",
    "        y = Y[-1]\n",
    "        post.append(y.tolist())\n",
    "\n",
    "    post = np.array(post)\n",
    "    y_pred[y_pred_uncertainty >= threshold] = post\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/oppo\\train.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-07 16:17:42,742][INFO] ## *** Example ***\n",
      "[2022-05-07 16:17:42,744][INFO] ## idx: 0\n",
      "[2022-05-07 16:17:42,746][INFO] ## tokens: [CLS] 喜 欢 打 篮 球 的 男 生 喜 欢 什 么 样 的 女 生 [SEP] 爱 打 篮 球 的 男 生 喜 欢 什 么 样 的 女 生 [SEP]\n",
      "[2022-05-07 16:17:42,747][INFO] ## input_ids: 1 692 811 445 2001 497 5 654 21 692 811 614 356 314 5 291 21 2 329 445 2001 497 5 654 21 692 811 614 356 314 5 291 21 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[2022-05-07 16:17:42,749][INFO] ## input_mask: 63\n",
      "[2022-05-07 16:17:42,750][INFO] ## segment_ids: 63\n",
      "[2022-05-07 16:17:42,753][INFO] ## label: 1\n",
      "[2022-05-07 16:23:53,670][INFO] ## shape: (534741, 63)\n",
      "[2022-05-07 16:24:08,991][INFO] ## Counter({0: 281960, 1: 252781})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/test/test.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-07 16:24:09,431][INFO] ## *** Example ***\n",
      "[2022-05-07 16:24:09,433][INFO] ## idx: 0\n",
      "[2022-05-07 16:24:09,434][INFO] ## tokens: [CLS] 李 成 儒 的 演 技 [SEP] 李 成 儒 的 书 [SEP]\n",
      "[2022-05-07 16:24:09,436][INFO] ## input_ids: 1 690 33 1945 5 493 164 2 690 33 1945 5 146 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[2022-05-07 16:24:09,437][INFO] ## input_mask: 63\n",
      "[2022-05-07 16:24:09,439][INFO] ## segment_ids: 63\n",
      "[2022-05-07 16:24:09,441][INFO] ## label: None\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name_or_path, do_lower_case=True)\n",
    "train_examples = read_examples(train_input, split='train')\n",
    "train_features = convert_examples_to_features(\n",
    "    train_examples, tokenizer, max_seq_length, True)\n",
    "\n",
    "all_input_ids = np.array(select_field(train_features, 'input_ids'))\n",
    "logger.info('shape: {}'.format(all_input_ids.shape))\n",
    "all_input_mask = np.array(select_field(train_features, 'input_mask'))\n",
    "all_segment_ids = np.array(select_field(train_features, 'segment_ids'))\n",
    "all_label = np.array([f.label for f in train_features])\n",
    "logger.info(Counter(all_label))\n",
    "\n",
    "test_examples = read_examples(test_input, split='test')\n",
    "test_features = convert_examples_to_features(\n",
    "    test_examples, tokenizer, max_seq_length, True)\n",
    "test_input_ids = torch.tensor(select_field(test_features, 'input_ids'), dtype=torch.long)\n",
    "test_input_mask = torch.tensor(select_field(test_features, 'input_mask'), dtype=torch.long)\n",
    "test_segment_ids = torch.tensor(select_field(test_features, 'segment_ids'), dtype=torch.long)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "oof_train = np.zeros((len(train_examples), 2), dtype=np.float32)\n",
    "oof_test = np.zeros((len(test_examples), 2), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-07 17:14:40,366][INFO] ## ================     fold 0        ===============\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [12:51<00:00,  3.46it/s]\n",
      "669it [00:45, 14.85it/s]\n",
      "[2022-05-07 17:28:24,321][INFO] ## epoch: 0, train loss: 0.34408181, valid loss: 0.28262713, acc: 0.87747431, f1: 0.87738309, best_f1: 0.87738309\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [13:02<00:00,  3.42it/s]\n",
      "669it [00:45, 14.70it/s]\n",
      "[2022-05-07 17:42:15,328][INFO] ## epoch: 1, train loss: 0.27214225, valid loss: 0.25576130, acc: 0.89276197, f1: 0.89252613, best_f1: 0.89252613\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [13:05<00:00,  3.40it/s]\n",
      "669it [00:45, 14.62it/s]\n",
      "[2022-05-07 17:56:10,228][INFO] ## epoch: 2, train loss: 0.24015898, valid loss: 0.24412773, acc: 0.90066293, f1: 0.90041902, best_f1: 0.90041902\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [13:01<00:00,  3.42it/s]\n",
      "669it [00:44, 14.88it/s]\n",
      "[2022-05-07 18:10:00,155][INFO] ## epoch: 3, train loss: 0.21465300, valid loss: 0.23868172, acc: 0.90442173, f1: 0.90417115, best_f1: 0.90417115\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [12:42<00:00,  3.51it/s]\n",
      "669it [00:44, 14.96it/s]\n",
      "[2022-05-07 18:23:30,569][INFO] ## epoch: 4, train loss: 0.19220681, valid loss: 0.23895742, acc: 0.90718941, f1: 0.90693067, best_f1: 0.90693067\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [12:43<00:00,  3.50it/s]\n",
      "669it [00:44, 14.95it/s]\n",
      "[2022-05-07 18:37:01,332][INFO] ## epoch: 5, train loss: 0.17255176, valid loss: 0.24169555, acc: 0.90865740, f1: 0.90840663, best_f1: 0.90840663\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [12:46<00:00,  3.49it/s]\n",
      "669it [00:44, 14.95it/s]\n",
      "[2022-05-07 18:50:35,508][INFO] ## epoch: 6, train loss: 0.15559332, valid loss: 0.24727979, acc: 0.90977943, f1: 0.90952800, best_f1: 0.90952800\n",
      "\n",
      "625it [00:40, 15.27it/s]\n",
      "[2022-05-07 18:51:17,871][INFO] ## epoch: best, acc: 0.90977943, f1: 0.90952800, best_f1: 0.90952800\n",
      "\n",
      "[2022-05-07 18:51:17,893][INFO] ## ================     fold 1        ===============\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [12:41<00:00,  3.51it/s]\n",
      "669it [00:44, 14.97it/s]\n",
      "[2022-05-07 19:04:51,357][INFO] ## epoch: 0, train loss: 0.34022175, valid loss: 0.28135707, acc: 0.87784718, f1: 0.87775792, best_f1: 0.87775792\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [12:42<00:00,  3.51it/s]\n",
      "669it [00:44, 14.93it/s]\n",
      "[2022-05-07 19:18:22,063][INFO] ## epoch: 1, train loss: 0.27216888, valid loss: 0.25245325, acc: 0.89424767, f1: 0.89401732, best_f1: 0.89401732\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [12:59<00:00,  3.43it/s]\n",
      "669it [00:45, 14.72it/s]\n",
      "[2022-05-07 19:32:09,961][INFO] ## epoch: 2, train loss: 0.24057692, valid loss: 0.24075326, acc: 0.90164379, f1: 0.90136528, best_f1: 0.90136528\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [12:58<00:00,  3.44it/s]\n",
      "669it [00:44, 14.92it/s]\n",
      "[2022-05-07 19:45:56,139][INFO] ## epoch: 3, train loss: 0.21517895, valid loss: 0.23549074, acc: 0.90588884, f1: 0.90564119, best_f1: 0.90564119\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2674/2674 [12:52<00:00,  3.46it/s]\n",
      "669it [00:44, 14.96it/s]\n",
      "[2022-05-07 19:59:36,309][INFO] ## epoch: 4, train loss: 0.19354991, valid loss: 0.23489968, acc: 0.90887160, f1: 0.90861890, best_f1: 0.90861890\n",
      "\n",
      " 25%|███████████████████▋                                                           | 665/2674 [03:13<09:46,  3.42it/s]"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, valid_index) in enumerate(skf.split(all_label, all_label)):\n",
    "    logger.info('================     fold {}        ==============='.format(fold))\n",
    "\n",
    "    # 处理模型输入数据\n",
    "    train_input_ids = torch.tensor(all_input_ids[train_index], dtype=torch.long)\n",
    "    train_input_mask = torch.tensor(all_input_mask[train_index], dtype=torch.long)\n",
    "    train_segment_ids = torch.tensor(all_segment_ids[train_index], dtype=torch.long)\n",
    "    train_label = torch.tensor(all_label[train_index], dtype=torch.long)\n",
    "\n",
    "    valid_input_ids = torch.tensor(all_input_ids[valid_index], dtype=torch.long)\n",
    "    valid_input_mask = torch.tensor(all_input_mask[valid_index], dtype=torch.long)\n",
    "    valid_segment_ids = torch.tensor(all_segment_ids[valid_index], dtype=torch.long)\n",
    "    valid_label = torch.tensor(all_label[valid_index], dtype=torch.long)\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(train_input_ids, train_input_mask, train_segment_ids, train_label)\n",
    "    valid = torch.utils.data.TensorDataset(valid_input_ids, valid_input_mask, valid_segment_ids, valid_label)\n",
    "    test = torch.utils.data.TensorDataset(test_input_ids, test_input_mask, test_segment_ids)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = NeuralNet(model_name_or_path).cuda()\n",
    "    model.cuda()\n",
    "    # model = nn.DataParallel(model, device_ids=[0, 1])\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # 优化器定义\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "    optimizer = RAdam(optimizer_grouped_parameters, lr=learning_rate, eps=1e-6)\n",
    "    total_steps = num_epochs * len(train_loader)\n",
    "    # scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=len(train_loader)*2, num_training_steps=total_steps)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_f1 = 0.\n",
    "    valid_best = np.zeros((valid_label.size(0), 2))\n",
    "\n",
    "    early_stop = 0\n",
    "    ema = EMA(model, 0.999)\n",
    "    ema.register()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.\n",
    "        lr_list = []\n",
    "        # if epoch > 2:\n",
    "        #     set_lr(optimizer, 2e-5)\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            batch = tuple(t.cuda() for t in batch)\n",
    "            x_ids, x_mask, x_sids, y_truth = batch\n",
    "            with autocast():\n",
    "                y_pred, loss = model(x_ids, x_mask, x_sids, y=y_truth, loss_fn=loss_fn)\n",
    "            scaler.scale(loss.mean()).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scale = scaler.get_scale()\n",
    "            scaler.update()\n",
    "            ema.update()\n",
    "            # skip_lr_sched = (scale != scaler.get_scale())\n",
    "            # if not skip_lr_sched:\n",
    "            #     scheduler.step()\n",
    "            train_loss += loss.mean().item() / len(train_loader)\n",
    "\n",
    "        ema.apply_shadow()\n",
    "        model.eval()\n",
    "        val_loss = 0.\n",
    "        valid_preds_fold = np.zeros((valid_label.size(0), 2))\n",
    "        with torch.no_grad():\n",
    "            for i, batch in tqdm(enumerate(valid_loader)):\n",
    "                batch = tuple(t.cuda() for t in batch)\n",
    "                x_ids, x_mask, x_sids, y_truth = batch\n",
    "                with autocast():\n",
    "                    y_pred, loss = model(x_ids, x_mask, x_sids, y_truth, loss_fn)\n",
    "                    y_pred = y_pred.detach()\n",
    "                    val_loss += loss.mean().item() / len(valid_loader)\n",
    "                valid_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "        acc, f1 = metric(all_label[valid_index], np.argmax(valid_preds_fold, axis=1))\n",
    "        if best_f1 < f1:\n",
    "            early_stop = 0\n",
    "            best_f1 = f1\n",
    "            valid_best = valid_preds_fold\n",
    "            torch.save(model.state_dict(), './model_save/ernie_' + file_name + '_{}.bin'.format(fold))\n",
    "        else:\n",
    "            early_stop += 1\n",
    "        logger.info(\n",
    "            'epoch: %d, train loss: %.8f, valid loss: %.8f, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "            (epoch, train_loss, val_loss, acc, f1, best_f1))\n",
    "        torch.cuda.empty_cache()  # 每个epoch结束之后清空显存，防止显存不足\n",
    "\n",
    "        # 检测早停\n",
    "        if early_stop >= patience:\n",
    "            break\n",
    "\n",
    "    # 得到一折模型对测试集的预测结果\n",
    "    model.load_state_dict(torch.load('./model_save/ernie_' + file_name + '_{}.bin'.format(fold)))\n",
    "    test_preds_fold = np.zeros((len(test_examples), 2))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(test_loader)):\n",
    "            batch = tuple(t.cuda() for t in batch)\n",
    "            x_ids, x_mask, x_sids = batch\n",
    "            with autocast():\n",
    "                y_pred = model(x_ids, x_mask, x_sids).detach()\n",
    "            test_preds_fold[i * batch_size:(i + 1) * batch_size] = F.softmax(y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "    oof_train[valid_index] = valid_best\n",
    "    acc, f1 = metric(all_label[valid_index], np.argmax(valid_best, axis=1))\n",
    "    logger.info('epoch: best, acc: %.8f, f1: %.8f, best_f1: %.8f\\n' %\n",
    "                (acc, f1, best_f1))\n",
    "    oof_test += test_preds_fold / 5\n",
    "\n",
    "# 保存概率文件\n",
    "np.savetxt('./submit/train_prob/train_bert_' + file_name + '.txt', oof_train)\n",
    "np.savetxt('./submit/test_prob/test_bert_' + file_name + '.txt', oof_test)\n",
    "acc, f1 = metric(all_label, np.argmax(oof_train, axis=1))\n",
    "logger.info('epoch: best, acc: %.8f, f1: %.8f \\n' % (acc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analysis = pd.DataFrame()\n",
    "analysis['s1'] = [line.s1 for line in train_examples]\n",
    "analysis['s2'] = [line.s2 for line in train_examples]\n",
    "analysis['label'] = [line.label for line in train_examples]\n",
    "analysis['pred'] = np.argmax(oof_train, axis=1).tolist()\n",
    "analysis[analysis['label'] != analysis['pred']].to_csv('analysis_{}.csv'.format(f1), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 后处理\n",
    "oof_test = prob_postprocess(oof_test)\n",
    "y_preds = np.argmax(oof_test, axis=1)\n",
    "logger.info(Counter(y_preds))\n",
    "\n",
    "with open('./output/predict_result_{}.csv'.format(f1), 'w', encoding=\"utf-8\") as f:\n",
    "    for y_pred in y_preds:\n",
    "        f.write(str(y_pred) + \"\\n\")\n",
    "\n",
    "\n",
    "def compare_pinyin(s1, s2):\n",
    "    s1_pinyin = \"\"\n",
    "    s2_pinyin = \"\"\n",
    "    for w in jieba.cut(s1):\n",
    "        s1_pinyin += ''.join(lazy_pinyin(w))\n",
    "    for w in jieba.cut(s2):\n",
    "        s2_pinyin += ''.join(lazy_pinyin(w))\n",
    "    return s1_pinyin == s2_pinyin\n",
    "\n",
    "\n",
    "def postprocess(data, pred):\n",
    "    post = []\n",
    "    for line, lable in tqdm(zip(data, pred)):\n",
    "        # r1 = correct(line.s1, line.s2)  # 339\n",
    "        r2 = compare_pinyin(line.s1, line.s2)  # 339\n",
    "        if r2:\n",
    "            post.append(1)\n",
    "        else:\n",
    "            post.append(lable)\n",
    "    post = np.array(post)\n",
    "    print(np.count_nonzero(post != pred))\n",
    "    return post\n",
    "\n",
    "\n",
    "post = postprocess(test_examples, y_preds)\n",
    "\n",
    "with open('./output/post_predict_result_{}.csv'.format(f1), 'w', encoding=\"utf-8\") as f:\n",
    "    for y_pred in post:\n",
    "        f.write(str(y_pred) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
