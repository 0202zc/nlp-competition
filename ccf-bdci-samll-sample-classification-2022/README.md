# CCF-BDCI 2022 小样本数据分类任务

## 赛程规划

该赛题采用初赛、决赛的“二级赛制”，具体赛程安排如下：

**2022/08/29-11/09，初赛阶段**

- 2022/08/29（12:00），发布大赛赛题，选手可登录大赛官网报名；
- 2022/09/05，开启初赛线上评测，选手可在线提交结果文件至竞赛平台，每日每队最多可提交3次，测评系统将自动评测得分并同步更新至排行榜。排行榜上将记录选手的最高成绩，相关团队必须自行保存最高成绩作品的源代码以备审核；
- 2022/11/04（12:00），截止报名组队；
- 2022/11/07（24:00），截止初赛A榜作品提交；初赛A榜评测结束后，所有选手均可进行初赛B榜评测；
- 2022/11/08，公布B榜测试集，本赛题所有参赛选手务必在11月08日24:00前，在本赛题“赛题数据”页下载B榜测试集；
- 2022/11/09（00:00-24:00），初赛B榜作品提交，参赛者可在B榜当天提交3次，但仅以每支团队当天最后一次提交进行评测，决赛入围资格以B榜线上最终成绩为准（B榜排行榜展示的成绩），若团队没有进行B榜提交，则无法晋级后续比赛，B榜TOP5团队经复现审核后入围决赛。

**2022/11/10-12/31，决赛阶段**

- 2022/11/10-11/20，复现及决赛资料提交，拟入围决赛的团队按照要求提交复现资料、决赛答辩评审资料等;
- 2022/11/26-11/27，决赛评审（线上）；
- 2022/12月中旬，决赛嘉年华系列活动（时间、场地待定，请关注通知）

## 项目介绍

#### 目录

- `baseline.ipynb`：训练和预测的主基线
- `baseline-data.ipynb`：数据后处理的基线
- `PromptClue.ipynb`：根据 PromptClue 修改的训练基线
- `**_classifier_**.py`：某方法以及某预训练模型的训练脚本（kfold的预测已包含在该对应的训练脚本内，每一折结束后自动进行测试集的预测，生成 `test_results_*.txt`文件）
- `**_pred_**.py`：预测脚本
- `modeling.py`：模型的代码
- `data/`：数据处理文件夹
  - `labels/`：各标签类别分离后的数据，用于采样
    - `split`：按策略对 `abstract` 列进行`<sep>`划分——[一种数据处理方法 - Datafountian](https://discussion.datafountain.cn/articles/detail/3622)
  - `prompt/`：用于 PromptClue 基线的数据集
  - `split/`：按策略划分 `abstract` 的数据集【有/无`assignee`：经测试，**无 `assignee` 数据的分数较高**】
  - `train/`、`test/`：有/未被划分过的数据集
  - `translation/`：中英文翻译数据集
  - `北京大学开放研究数据平台_发明专利数据`：额外数据（来源：[北京大学开放研究数据平台-发明专利数据](https://discussion.datafountain.cn/articles/detail/3601)）
    - 取28000条数据（相当于A榜测试集的20839条）进行伪标签方式训练，发现略有提升：0.6452 → 0.6453
    - 取40000条数据进行伪标签方式训练，效果不升反降：可能因为噪声过大导致
- `tools/`：NEZHA 官方 baseline 带的工具

#### 方法

- 尝试过：

  -  BERT、RoBERTa、NEZHA、BertForPatents、XLNet模型，发现 XLNet 分数最高
  - 中英文回译加入数据集、纯英文 + BertForPatents，发现使用中文回译训练集分数较高
  - 伪标签：现预测出的A榜测试集（分数0.6453）与训练集的原始分布不同，类别`0`和`4`明显偏多（参考 `data/data.ipynb` 中的柱状图）
    - 加入外部数据集，效果参考上述内容。
  - mixup 方法，训练效果不佳，震荡

- 本任务 baseline 采用的方法： 

  - XLNet 预训练模型
  - (有/无 BiGRU + ) Transformer Encoder
  - 5-Fold Cross-validation
  - RDropLoss (focal loss) 
  - 分层学习率 + 线性学习率预热：预训练模型参数 `1e-5`，分类层参数 `3e-5`，4 epochs，32~40 batch size 【使用两张 NVIDIA RTX A5000 显卡】

  - 采用伪标签的方式（`data/data.ipynb`）：利用训练集训练模型，然后模型预测测试集标签，再将这些标签**按比例策略**加入训练集

## TODO (2022-11-05)

- 测试集标签加入训练集过多，导致噪声增大，模型效果无法提升
- 训练次数过多引起过拟合，可能在B榜上的成绩不高

## 比赛结果

### A 榜（2022-11-08 23:59:59 截止 / 前十名）

| 排名    | 队伍名称        | 有效提交次数 | 最高分提交时间       | 最高得分       |
| ------- | --------------- | ------------ | -------------------- | -------------- |
| 1       | default13188354 | 91           | 2022-11-05 10:46     | 0.65780034     |
| 2       | 龙盈战队        | 156          | 2022-11-07 11:01     | 0.65739203     |
| 3       | nlp小菜鸡       | 117          | 2022-11-07 12:45     | 0.65680602     |
| *4*     | default13218484 | 39           | 2022-11-06 16:57     | 0.65350067     |
| *5*     | 东油詹姆斯      | 133          | 2022-11-05 00:04     | 0.65159929     |
| *6*     | 痛！太痛了！    | 188          | 2022-11-07 22:55     | 0.65159296     |
| *7*     | RNG             | 39           | 2022-11-06 20:32     | 0.65043940     |
| *8*     | default13212794 | 74           | 2022-11-06 23:24     | 0.64960820     |
| ***9*** | **Betalemon**   | **154**      | **2022-11-07 23:57** | **0.64950911** |
| *10*    | Pris_cc         | 33           | 2022-11-07 21:23     | 0.64526703     |

### B 榜（2022-11-09 23:59:59 截止）

| 排名 | 队伍名称 | 最高分提交时间 | 最高得分 |
| :--- | :------: | :------------: | :------: |
| 1 | default13216590 | 2022-11-09 13:41 | 0.61638948 |
| 2 | nlp小菜鸡       | 2022-11-09 16:18 | 0.61387745 |
| 3 | 躺平不如起立    | 2022-11-09 21:56 | 0.61336298 |
| *4*  | default13216979 | 2022-11-09 22:05 | 0.61245633 |
| *5*  | default13216522 | 2022-11-09 18:35 | 0.60958329 |
| *6*  | 轻薄的假象      | 2022-11-09 08:13 | 0.60758977 |
| *7*  | 东油詹姆斯      | 2022-11-09 19:59 | 0.60744526 |
| *8*  | default13221780 | 2022-11-09 18:40 | 0.60688546 |
| *9*  | 南山忆          | 2022-11-09 22:12 | 0.60396312 |
| *9*  | default13221764 | 2022-11-09 22:17 | 0.60396312 |
| *11* | 黑黑的触手            | 2022-11-09 23:50 | 0.60303088 |
| *12* | 飞机炸弹              | 2022-11-09 16:36 | 0.60230478 |
| *13* | default7644130        | 2022-11-09 18:12 | 0.60060463 |
| *14* | awesome-patent-mining | 2022-11-09 18:35 | 0.59891651 |
| *15* | 痛！太痛了！          | 2022-11-09 10:11 | 0.59547145 |
| *16* | default13216537       | 2022-11-09 18:57 | 0.59540154 |
| *17* | default13222352       | 2022-11-09 20:37 | 0.59539890 |
| *18* | TinyJJ                | 2022-11-09 14:06 | 0.59536446 |
| *19* | RNG                   | 2022-11-09 10:20 | 0.59522346 |
| *20* | Pris_cc               | 2022-11-09 13:42 | 0.59354430 |
| *21* | 龙盈战队         | 2022-11-09 16:24 | 0.59259108 |
| *22* | default13220091  | 2022-11-09 16:05 | 0.59212725 |
| *23* | wabbybabo        | 2022-11-09 16:02 | 0.59172498 |
| *24* | ABC              | 2022-11-09 23:36 | 0.59046205 |
| *25* | 糖醋鱼           | 2022-11-09 11:18 | 0.58979901 |
| *26* | 1！5！           | 2022-11-09 13:56 | 0.58964467 |
| *27* | 云子宝宝520      | 2022-11-09 17:26 | 0.58929123 |
| *28* | default13220530  | 2022-11-09 18:37 | 0.58919866 |
| *29* | default13188354  | 2022-11-09 10:07 | 0.58893567 |
| *30* | default138276273 | 2022-11-09 08:32 | 0.58688516 |
| *31* | EEEEEEE              | 2022-11-09 20:14 | 0.58555292 |
| *32* | default13219846      | 2022-11-09 16:40 | 0.58529877 |
| *33* | 于万人中万幸得以相逢 | 2022-11-09 20:45 | 0.58258701 |
| *34* | 菜鸟当道             | 2022-11-09 17:56 | 0.58198794 |
| *35* | 水水更健康           | 2022-11-09 09:14 | 0.58196135 |
| *36* | 玟岚                 | 2022-11-09 16:15 | 0.57762542 |
| *37* | default13223371      | 2022-11-09 17:15 | 0.57519927 |
| *38* | zeroooooo            | 2022-11-09 21:13 | 0.57428694 |
| *39* | default13182462      | 2022-11-09 16:44 | 0.56975996 |
| *40* | default7652283       | 2022-11-09 21:47 | 0.56952988 |
| *41* | 小皮不会NLP     | 2022-11-09 23:28 | 0.56884551 |
| *42* | default13216134 | 2022-11-09 09:42 | 0.56792494 |
| *43* | 妮可机器学习队  | 2022-11-09 19:32 | 0.56586349 |
| ***44*** | **Betalemon**   | **2022-11-09 23:47** | **0.56427789** |
| *45* | default7668121  | 2022-11-09 16:31 | 0.56416206 |
| *46* | ggg             | 2022-11-09 19:58 | 0.56326034 |
| *47* | default13227318 | 2022-11-09 17:09 | 0.56284986 |
| *48* | 数据挖得不队    | 2022-11-09 10:14 | 0.56107833 |
| *49* | default7681056  | 2022-11-09 23:14 | 0.56107181 |
| *50* | 12345           | 2022-11-09 16:49 | 0.55995026 |
| *51* | 四散天涯        | 2022-11-09 10:59 | 0.55947060 |
| *52* | default13227566 | 2022-11-09 12:10 | 0.55891351 |
| *53* | Can Can World   | 2022-11-09 09:59 | 0.55777776 |
| *54* | default7679499  | 2022-11-09 18:22 | 0.55635218 |
| *55* | kxjl_gogogo     | 2022-11-09 11:01 | 0.55615195 |
| *56* | 一个诸葛亮      | 2022-11-09 16:01 | 0.55543803 |
| *57* | default13228226 | 2022-11-09 11:20 | 0.55484096 |
| *58* | hhh             | 2022-11-09 10:47 | 0.55235556 |
| *59* | default13217904 | 2022-11-09 22:06 | 0.55201079 |
| *60* | 呃呃呃          | 2022-11-09 10:17 | 0.55065931 |
| *61* | default7699532  | 2022-11-09 21:41 | 0.55020015 |
| *62* | default13187150 | 2022-11-09 15:02 | 0.55001049 |
| *63* | 炒饭的队伍      | 2022-11-09 02:38 | 0.54985840 |
| *64* | CCF冲冲冲       | 2022-11-09 21:33 | 0.54800893 |
| *65* | default13212362 | 2022-11-09 15:26 | 0.54792756 |
| *66* | 去码头搞点薯片  | 2022-11-09 14:30 | 0.54765438 |
| *67* | lalala          | 2022-11-09 19:57 | 0.54467654 |
| *68* | 我不对谁队      | 2022-11-09 23:30 | 0.54453249 |
| *69* | default13211260 | 2022-11-09 20:11 | 0.54359466 |
| *70* | default13228271 | 2022-11-09 00:07 | 0.54328677 |
| *71* | default13223879 | 2022-11-09 12:39 | 0.54121300 |
| *72* | default13210539 | 2022-11-09 20:40 | 0.53815300 |
| *73* | 卡纳西尼诺乌米  | 2022-11-09 22:34 | 0.53574768 |
| *74* | default13217291 | 2022-11-09 18:53 | 0.53559068 |
| *75* | default7673849  | 2022-11-09 20:42 | 0.53534857 |
| *76* | default7636467  | 2022-11-09 19:25 | 0.53373139 |
| *77* | default13227589 | 2022-11-09 13:43 | 0.53372082 |
| *78* | default13218959 | 2022-11-09 17:19 | 0.52995926 |
| *79* | 队伍名          | 2022-11-09 09:15 | 0.52862836 |
| *80* | 瀚星银河        | 2022-11-09 17:27 | 0.52537185 |
| *81* | default7615721  | 2022-11-09 22:08 | 0.52370749 |
| *82* | 运控部NO1       | 2022-11-09 13:15 | 0.52339707 |
| *83* | shallowdream303 | 2022-11-09 21:37 | 0.52331815 |
| *84* | 挖都可以挖      | 2022-11-09 07:34 | 0.52241840 |
| *85* | default7667932  | 2022-11-09 09:12 | 0.52181572 |
| *86* | default13223419 | 2022-11-09 11:56 | 0.52080780 |
| *87* | default13175848 | 2022-11-09 21:55 | 0.51958745 |
| *88* | 能run就算成功   | 2022-11-09 16:17 | 0.51903903 |
| *89* | FZU_LHW         | 2022-11-09 22:32 | 0.51892731 |
| *90* | default7641560  | 2022-11-09 13:32 | 0.51490042 |
| *91*  | MeMine          | 2022-11-09 21:10 | 0.51459419 |
| *92*  | 菜鸟的秋天      | 2022-11-09 00:05 | 0.51432552 |
| *93*  | 上山打老虎      | 2022-11-09 08:37 | 0.51406287 |
| *94*  | 啊对对对队      | 2022-11-09 16:46 | 0.51390141 |
| *95*  | 和我一起抓水母  | 2022-11-09 07:41 | 0.51250445 |
| *96*  | TUT.NO1         | 2022-11-09 21:08 | 0.51056523 |
| *97*  | wyn的队伍       | 2022-11-09 10:09 | 0.50886171 |
| *98*  | 小太阳          | 2022-11-09 21:12 | 0.50735416 |
| *99*  | 海淀彭于晏      | 2022-11-09 15:27 | 0.50707683 |
| *100* | default13210385 | 2022-11-09 23:57 | 0.50707348 |
| *101* | ML5             | 2022-11-09 09:12 | 0.50518410 |
| *102* | aaaxcv          | 2022-11-09 11:45 | 0.50317489 |
| *103* | 数据科学家      | 2022-11-09 16:18 | 0.50198839 |
| *104* | default13217054 | 2022-11-09 20:08 | 0.49628334 |
| *105* | USAI2022        | 2022-11-09 22:31 | 0.49529773 |
| *106* | orbrd           | 2022-11-09 23:55 | 0.48776344 |
| *107* | millionStars    | 2022-11-09 10:58 | 0.47790895 |
| *108* | 呱呱今天吃什么  | 2022-11-09 23:23 | 0.47618487 |
| *109* | default13212401 | 2022-11-09 09:07 | 0.47404458 |
| *110* | IT牛马队        | 2022-11-09 14:33 | 0.46480657 |
| *111* | default13214020 | 2022-11-09 08:24 | 0.46155886 |
| *112* | 我们都是DM菜鸡  | 2022-11-09 18:00 | 0.44936376 |
| *113* | [MASK]科大      | 2022-11-09 11:44 | 0.34388725 |
| *114* | 725ExceptHua-Yu | 2022-11-09 22:27 | 0.26668004 |
| *115* | 你是风儿我是啥  | 2022-11-09 19:42 | 0.20574068 |
| *116* | AC              | 2022-11-09 23:48 | 0.19993247 |
| *117* | 玉泉路小队      | 2022-11-09 23:55 | 0.04384257 |
| *118* | default7636169  | 2022-11-09 14:29 | 0.02558219 |
| *119* | default13211878 | 2022-11-09 22:47 | 0.02399520 |
| *120* | default13222839 | 2022-11-09 19:52 | 0.02002957 |
| *121* | default13224833 | 2022-11-09 16:52 | 0.01198853 |
| *122* | default13210303 | 2022-11-09 11:38 | 0.00331323 |
| *123* | default13205466 | 2022-11-09 12:50 | 0.00189517 |
| *123* | default13220270 | 2022-11-09 15:52 | 0.00189517 |

## 总结（2022-11-10）

经过三个月的炼丹和调试终于在“抖榜”中结束了。之前想到会过拟合，在没想到B榜的结果会这么拉。过拟合可能有下面几个部分：

> testA 和 testB 其真实标签的分布与 train 的分布一致（分层抽样）。testA 与 testB 的数量比接近 1:1

- 过采样的比例问题：
  - 【生成初始伪标签】首先利用训练好的A榜最高分 0.6495 的模型生成B榜的伪标签；
  - 【train + train_backtranslation + testA6495 + testB】将训练集加上回译的部分（训练集数量 * 2），同时加上 testA 的最高分伪标签（总共四万多条数据）；
  - 以 `lr=3e-5`、`batch size=40` 替换伪标签地反复训练 `4epochs`两次，得到最总的 testB 伪标签；
  - 以每个标签50倍 tain.json 过采样，超过50倍的，给予24倍的限额；低于50倍的，给予1倍的容忍；
  - 这样过采样出来，testB 中标签为0的文本很多没有被采集到，而那些只有几倍的标签（22）数量又过多。
- 使用了 testA 的伪标签训练 testB，其自身有偏差，可能导致最后整体偏差过大。
- 文本处理：按规则分割后，只取了title和effect拼接作为输入（按照 testA 最高分的策略，即 `测试时数据增强（TTA）方式`），可能丢失了文本其他部分的信息。

**本次在B榜测试集中失败的原因大概率是过拟合。**若时间充裕可尝试加入 abstract 文本的全部部分进行训练。

借用与 @Zhou.Y.M 大佬的谈话记录：

> 好不好不是看分数，是看背后的逻辑。你想一个道理。比如有10个参数，你不思考 只是去乱调，调了马上能看到调得好不好，那谁都能把他调好，打比赛不是调参。

---

### 赛题群交流记录 （2022-11-10）

#### @覃辉

哈，这抖动也太厉害了。昨天做两个蒸馏模型的对比测试，A榜上差了十几个标签，在B榜的预测上却有了600多个标签的差异。我们预计会有0.03左右的抖动。没想到比这还厉害。

简单交流一下吧。前期，我们使用两种数据增强(后向翻译和随机调换邻近词的位置）创造新的数据，再用类似这样(`'这篇专利的类别是[MASK]。' + line['title'] + '。' + line['assignee'] + '。' + line['abstract']`)文本组合方式, 选用Roberta large 4fold，分数早早就到了0.62x。又换了其它的预训练模型训练，简单融合分数就上了0.63. 到了比赛中段，我们主要靠伪标签来提升单模，通过不同的预训练模型融合来提升总分。分数也很快上了0.65 。
伪标签策略：
1）不同分类取不同概率阈值，对数量多的分类随机采样，最后组合的时候尽量和train的分类比例靠近；
2）不同分类取不同概率阈值，通过4fold的精准率和召回率来选择最佳阈值，对数量多的分类随机采样；
3）伪标签数量大概13k左右

这比赛work的trick：
1）后向翻译和随机调换邻近词的位置；
2）R-DROP，MULTI-DROPOUT，对抗训练，分层学习率；
3）伪标签；
4）简单的MASK学习。类似：这篇专利的类别是[MASK]
5）百度的ERNIE 3.0预训练模型很好用。效果比各种large都好。

不work的：
1）UDA以及某些半监督的论文
2）MLM预训练
3）换不同的种子。我们用42的种子和lb比较配合，换了别的种子，分数就跌了很多。
4）英文bert for pattern。不管是base还是large，lb 都很差，都不如ERNIE 3.0
5）同义词和近义词数据增强

以上就是我们拟合A榜的过程，欢迎交流。

这个比赛在train数据上还是有些小问题的。主要是那几个小分类(标注样本很少的)。有些只有5条标注数据，但是里面的样本却分属多个领域。以至于有些领域只有一条数据。这样的样本，就很容易被分类器分到别的分类去了。如果每个领域至少两条数据的话，这些小分类的F1值可能就会好很多

---
Q: 大佬 那个mask学习是指的prompt吗

A: 我们不是sequence-2-sequence的方式，而是这样：

```python
hidden_layers = outputs[-1]
cls_outputs = torch.stack(
    [layer[:, 9, :] for layer in hidden_layers], dim=2
)
```

所以，应该还是算`MASK`吧

#### @HY

我单模最高0.611 就用chinese-bert-wwm-ext  也不用伪标签 也不用数据增强 用了 label smooth 都是去拟合数据 我还去推了 A测试集 每个label应该有多少个。。。
2:3357   11:1114   10:1074 0:695 8:816  5:755 6:976 。。。。。
每次推理的结果中  0 和 10 都出现2100个。。。。。大部分错的就在这里。。。我就想各种采样呀之类的 都没有搞上去
数据增强想采用backtranslate 发现API限流 。。。。就用了预训练翻译模型，效果太差了 。。。 

我几乎把所有的预训练模型都尝试了一遍。。。roberta bert ernie1.0/ 3.0/  gram  macbert nezha deberta-v2 mengzi_bert  最后得出chinese-bert-wwm-ex效果最好 就一直采用这个模型

覃辉：@HY 谢谢分享。我们也是用预训练翻译模型的。但是BT（后向翻译）增强确实有用

#### @ 坤坤 四川

我一直在处理数据，5号都还在处理数据，然后不加trick在A榜0.628

最后也没时间加伪标签那些了

训练时把assignee去掉，推理时加上后缀为“有限公司”的assignee

拆分也没必要拆成三部分，只需要把最后的effect拆出来，效果要好一些

覃辉：@坤坤 四川 你是单折0.628吗？这分数不错的。

坤坤 四川：嗯

覃辉：嗯嗯，bert for patents吗？

坤坤 四川：是的

#### @ DECEM 深圳

很早前随便试了easynlp里面的一个prompt方法，效果不太好，base也才0.5。用的是标签语义。

