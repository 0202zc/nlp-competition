# CCF-BDCI 2022 小样本数据分类任务

## 赛程规划

该赛题采用初赛、决赛的“二级赛制”，具体赛程安排如下：

> **2022/08/29-11/09，初赛阶段**
> ▪ 2022/08/29（12:00），发布大赛赛题，选手可登录大赛官网报名；
> ▪ 2022/09/05，开启初赛线上评测，选手可在线提交结果文件至竞赛平台，每日每队最多可提交3次，测评系统将自动评测得分并同步更新至排行榜。排行榜上将记录选手的最高成绩，相关团队必须自行保存最高成绩作品的源代码以备审核；
> ▪ 2022/11/04（12:00），截止报名组队；
> ▪ 2022/11/07（24:00），截止初赛A榜作品提交；初赛A榜评测结束后，所有选手均可进行初赛B榜评测；
> ▪ 2022/11/08，公布B榜测试集，本赛题所有参赛选手务必在11月08日24:00前，在本赛题“赛题数据”页下载B榜测试集；
> ▪ 2022/11/09（00:00-24:00），初赛B榜作品提交，参赛者可在B榜当天提交3次，但仅以每支团队当天最后一次提交进行评测，决赛入围资格以B榜线上最终成绩为准（B榜排行榜展示的成绩），若团队没有进行B榜提交，则无法晋级后续比赛，B榜TOP5团队经复现审核后入围决赛。

> **2022/11/10-12/31，决赛阶段**
> ▪ 2022/11/10-11/20，复现及决赛资料提交，拟入围决赛的团队按照要求提交复现资料、决赛答辩评审资料等;
> ▪ 2022/11/26-11/27，决赛评审（线上）；
> ▪ 2022/12月中旬，决赛嘉年华系列活动（时间、场地待定，请关注通知）

## 项目介绍

#### 目录

- `baseline.ipynb`：训练和预测的主基线
- `baseline-data.ipynb`：数据后处理的基线
- `PromptClue.ipynb`：根据 PromptClue 修改的训练基线
- `**_classifier_**.py`：某方法以及某预训练模型的训练脚本（kfold的预测已包含在该对应的训练脚本内，每一折结束后自动进行测试集的预测，生成 `test_results_*.txt`文件）
- `**_pred_**.py`：预测脚本
- `modeling.py`：模型的代码
- `data/`：数据处理文件夹
  - `labels/`：各标签类别分离后的数据，用于采样
    - `split`：按策略对 `abstract` 列进行`<sep>`划分——[一种数据处理方法 - Datafountian](https://discussion.datafountain.cn/articles/detail/3622)
  - `prompt/`：用于 PromptClue 基线的数据集
  - `split/`：按策略划分 `abstract` 的数据集【有/无`assignee`：经测试，**无 `assignee` 数据的分数较高**】
  - `train/`、`test/`：有/未被划分过的数据集
  - `translation/`：中英文翻译数据集
  - `北京大学开放研究数据平台_发明专利数据`：额外数据（来源：[北京大学开放研究数据平台-发明专利数据](https://discussion.datafountain.cn/articles/detail/3601)）
    - 取28000条数据（相当于A榜测试集的20839条）进行伪标签方式训练，发现略有提升：0.6452 → 0.6453
    - 取40000条数据进行伪标签方式训练，效果不升反降：可能因为噪声过大导致
- `tools/`：NEZHA 官方 baseline 带的工具

#### 方法

- 尝试过：

  -  BERT、RoBERTa、NEZHA、BertForPatents、XLNet模型，发现 XLNet 分数最高
  - 中英文回译加入数据集、纯英文 + BertForPatents，发现使用中文回译训练集分数较高
  - 伪标签：现预测出的A榜测试集（分数0.6453）与训练集的原始分布不同，类别`0`和`4`明显偏多（参考 `data/data.ipynb` 中的柱状图）
    - 加入外部数据集，效果参考上述内容。
  - mixup 方法，训练效果不佳，震荡

- 本任务 baseline 采用的方法： 

  - XLNet 预训练模型
  - (有/无 BiGRU + ) Transformer Encoder
  - 5-Fold Cross-validation
  - RDropLoss (focal loss) 
  - 分层学习率 + 线性学习率预热：预训练模型参数 `1e-5`，分类层参数 `3e-5`，4 epochs，32~40 batch size 【使用两张 NVIDIA RTX A5000 显卡】

  - 采用伪标签的方式（`data/data.ipynb`）：利用训练集训练模型，然后模型预测测试集标签，再将这些标签**按比例策略**加入训练集

## TODO

- 测试集标签加入训练集过多，导致噪声增大，模型效果无法提升
- 训练次数过多引起过拟合，可能在B榜上的成绩不高

